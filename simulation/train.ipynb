{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9378, 1.8699, 0.5784, 0.9926, 0.9102],\n",
      "        [1.1373, 1.1477, 0.5278, 1.7049, 1.1137],\n",
      "        [0.7076, 1.4236, 1.3848, 1.7648, 1.3178],\n",
      "        [1.8808, 2.3128, 1.0802, 1.2985, 1.7595]])\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-implement-keras-layers-core-lambda-in-pytorch/5903\n",
    "class BestMeanPooling(nn.Module):\n",
    "    \n",
    "  def __init__(self, n_topN):\n",
    "    super(BestMeanPooling, self).__init__()\n",
    "    self.topN = n_topN\n",
    "        \n",
    "  def forward(self, aX_tr):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    aX_tr_sorted, _ = torch.sort(aX_tr, axis=1) # also return index\n",
    "    return torch.mean(aX_tr_sorted[:, -self.topN:,:], axis=1)\n",
    "    # print(\"B = \", aX_tr_sorted.size(), aX_tr_sorted)\n",
    "    # c = torch.mean(aX_tr_sorted[:, -self.topN:,:], axis=1)\n",
    "    # print(\"C = \", c.size(), c)\n",
    "    return c\n",
    "\n",
    "# Test\n",
    "aA = torch.randn(1, 200).reshape(4, 10, 5)\n",
    "mean_pool = BestMeanPooling(2) \n",
    "aA = mean_pool(aA)\n",
    "print(aA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticData(Dataset):\n",
    "    def __init__(self, upper, x, y, z):\n",
    "      self.aX_tr_sy = np.random.random_sample(upper).reshape(x, y, z)\n",
    "      self.ay_tr_sy = np.random.randint(0, 2, x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.aX_tr_sy)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.aX_tr_sy[idx], self.ay_tr_sy[idx] #.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MassCNN(nn.Module):\n",
    "\n",
    "  def __init__(self, n_in, n_out, num_event=10, topN=5, prob=0.00):\n",
    "    super(MassCNN,self).__init__()\n",
    "    self.n_filter = n_out\n",
    "\n",
    "    #first layers\n",
    "    self.conv_1        = nn.Conv1d(n_in, n_out, kernel_size=1)\n",
    "    \n",
    "    # output of the layer is # of filters\n",
    "    self.bmpool_1      = BestMeanPooling(topN)\n",
    "    self.dropout_L1    = nn.Dropout(p=prob)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    self.fcn_1 = nn.Linear(3, 2)\n",
    "    # self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, aX_tr):\n",
    "    aX_tr = self.conv_1(aX_tr)\n",
    "    aX_tr = torch.relu(aX_tr)\n",
    "    \n",
    "    # This will collapse one dimension\n",
    "    aX_tr = self.bmpool_1(aX_tr)\n",
    "    \n",
    "    if self.n_filter > 4: \n",
    "      aX_tr = self.dropout_L1(aX_tr)\n",
    "    \n",
    "    aX_tr = aX_tr.view(aX_tr.size(0), -1)\n",
    "    aX_tr = self.fcn_1(aX_tr)\n",
    "    # aX_tr = self.softmax(aX_tr)\n",
    "    return aX_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs=10, lr=0.1, filter=12):\n",
    "    \"\"\"\n",
    "      Aim:\n",
    "\n",
    "      params:\n",
    "\n",
    "      returns:\n",
    "    \"\"\"\n",
    "    # Random data\n",
    "    d_trains = SyntheticData(750, 5, 50, 3)\n",
    "    d_valids = SyntheticData(750, 5, 50, 3)\n",
    "    d_tests  = SyntheticData(750, 5, 50, 3)\n",
    "    \n",
    "    # \n",
    "    massModel = MassCNN(50, filter, 3, 5)\n",
    "    \n",
    "    # Trying to remove this type casting from here.\n",
    "    massModel = massModel #.float()\n",
    "    \n",
    "    # optimization\n",
    "    optimizer = torch.optim.SGD(massModel.parameters(), lr=0.0001)\n",
    "    fcost     = torch.nn.CrossEntropyLoss()\n",
    "  \n",
    "    cost_per_epoch = []\n",
    "    \n",
    "    aTrs = DataLoader(d_trains, batch_size=100, shuffle=True)\n",
    "    aVas = DataLoader(d_valids, batch_size=10, shuffle=True)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "      fgr_cost = 0\n",
    "      for x, y in aTrs:\n",
    "        ## Back propagation the loss\n",
    "        optimizer.zero_grad()\n",
    "        y_pr  = massModel(x.float())\n",
    "        loss  = fcost(y_pr, y)\n",
    "        loss.backward()\n",
    "        optimizer.step() # back propagate\n",
    "        fgr_cost += loss.data\n",
    "      cost_per_epoch.append(fgr_cost)\n",
    "    \n",
    "      correct=0\n",
    "      for x_va, y_va in aVas:\n",
    "        z  = massModel(x_va.float()).data\n",
    "        temp, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat == y_va).sum().item()\n",
    "      accuracy = correct / 1000\n",
    "      print(epoch, accuracy)\n",
    "            \n",
    "      # get accuracy list \n",
    "    #return f_ac_va\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.002\n",
      "1 0.002\n",
      "2 0.002\n",
      "3 0.002\n",
      "4 0.002\n",
      "5 0.002\n",
      "6 0.002\n",
      "7 0.002\n",
      "8 0.002\n",
      "9 0.002\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 20, 5)\n",
      "(None, 20, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=(None, 20, 10) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Activation, Dropout\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# the input layer\n",
    "ncell = 20\n",
    "nmark = 5\n",
    "data_input = Input(shape=(ncell, nmark))\n",
    "\n",
    "nfilter = 10\n",
    "# the filters\n",
    "print(data_input.shape)\n",
    "conv = Convolution1D(nfilter, 1, activation='linear', name='conv1')(data_input)\n",
    "print(conv.shape)\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "K.print_tensor(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=7, stride=1, padding=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n",
      "torch.Size([5, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "in_channel = 16\n",
    "out_channel = 33\n",
    "filter/kernal = 3\n",
    "batch = 20\n",
    "\"\"\"\n",
    "\n",
    "m = nn.Conv1d(3, 6, 2, stride=1)\n",
    "input = torch.randn(5, 3, 4)\n",
    "print(input.shape)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7028, -0.6217,  0.4973, -2.2627],\n",
       "         [ 0.4807,  0.8496, -0.9030, -0.5538],\n",
       "         [ 1.9475,  0.6171, -0.7366, -0.2498]],\n",
       "\n",
       "        [[ 0.6387, -0.5125, -1.0771, -0.9551],\n",
       "         [-0.5356,  0.9956,  0.0584,  2.2914],\n",
       "         [-1.5711, -0.9820, -0.0799,  3.0789]],\n",
       "\n",
       "        [[-1.0428, -1.6745, -0.7521,  0.0911],\n",
       "         [ 0.3217, -0.2753,  1.3601,  0.6509],\n",
       "         [ 1.0648, -2.2526, -0.4646, -0.7599]],\n",
       "\n",
       "        [[ 0.2886,  0.4290,  0.1780, -0.8287],\n",
       "         [-0.0234, -0.7935, -1.6031, -0.0356],\n",
       "         [ 2.6638, -0.7362,  1.1084,  1.2157]],\n",
       "\n",
       "        [[ 2.1391,  0.4881, -0.3508,  0.7002],\n",
       "         [-1.2184,  1.3413, -1.0789, -0.1223],\n",
       "         [-0.9552, -0.6782, -1.9579,  0.7080]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1031e-01,  1.0137e+00, -3.1264e-01],\n",
       "         [ 5.8147e-01,  8.2541e-01, -1.3561e-01],\n",
       "         [-1.8212e-01,  1.0984e-01, -5.3305e-01],\n",
       "         [ 6.0273e-01,  1.2084e-01, -4.7400e-01],\n",
       "         [ 9.2841e-01,  5.8898e-02, -1.8112e-01],\n",
       "         [ 5.4575e-01, -1.2519e-01,  1.5662e-01]],\n",
       "\n",
       "        [[-5.7114e-01, -2.7715e-01, -1.1713e+00],\n",
       "         [-5.2369e-01, -4.3964e-01, -5.6885e-01],\n",
       "         [-4.7010e-01, -2.9353e-01,  7.1560e-01],\n",
       "         [ 4.7868e-02, -2.4236e-01,  1.1398e+00],\n",
       "         [-5.5377e-01, -6.1071e-01,  9.3415e-01],\n",
       "         [ 2.7050e-01, -1.4577e-01,  1.0217e+00]],\n",
       "\n",
       "        [[ 1.2452e+00, -5.4066e-01,  1.8155e-01],\n",
       "         [ 3.7294e-01, -9.6781e-01, -2.0210e-01],\n",
       "         [-1.2265e+00, -2.0285e-01, -2.8817e-01],\n",
       "         [-8.2457e-01, -4.9723e-02,  5.2548e-02],\n",
       "         [-7.5778e-01, -1.0015e+00, -6.2687e-01],\n",
       "         [ 2.9532e-02,  3.5118e-01, -6.4301e-02]],\n",
       "\n",
       "        [[ 1.5545e+00, -4.4594e-02,  1.6927e-01],\n",
       "         [ 1.6631e+00,  7.4171e-01,  8.5054e-01],\n",
       "         [ 7.2260e-04,  9.8148e-01,  4.6613e-01],\n",
       "         [ 4.5139e-01,  5.2193e-01,  7.0695e-01],\n",
       "         [ 1.0402e+00,  8.4894e-01,  1.3676e+00],\n",
       "         [ 3.3960e-01,  9.5333e-02,  8.7697e-01]],\n",
       "\n",
       "        [[-6.8655e-01,  4.9101e-01, -4.5058e-01],\n",
       "         [-4.7049e-02,  1.1297e-01,  5.3361e-02],\n",
       "         [-1.4475e-01, -7.2109e-01,  9.4240e-01],\n",
       "         [ 7.3098e-01, -6.3197e-01,  7.0714e-01],\n",
       "         [ 2.9957e-01, -9.7242e-01,  2.8977e-01],\n",
       "         [ 5.8629e-01, -6.4705e-01,  3.6014e-01]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
